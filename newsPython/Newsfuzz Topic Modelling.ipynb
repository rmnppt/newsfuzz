{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from the mysql server and throw it into a dataframe\n",
    "engine = create_engine('mysql+pymysql://newsfuzz:newsfuzzplease@newsfuzz.cuhvcgseshha.eu-west-2.rds.amazonaws.com:3306/newsfuzz', encoding='utf-8')\n",
    "newsfuzz_db = pd.io.sql.read_sql('SELECT * FROM newsfuzz_db_test', engine, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11114\n",
      "array(['abc-news-au', 'al-jazeera-english', 'ars-technica',\n",
      "       'associated-press', 'bbc-news', 'bbc-sport', 'bild', 'bloomberg',\n",
      "       'breitbart-news', 'business-insider', 'business-insider-uk',\n",
      "       'buzzfeed', 'cnbc', 'cnn', 'daily-mail', 'engadget',\n",
      "       'entertainment-weekly', 'espn', 'espn-cric-info', 'financial-times',\n",
      "       'focus', 'football-italia', 'fortune', 'four-four-two',\n",
      "       'fox-sports', 'google-news', 'gruenderszene', 'hacker-news', 'ign',\n",
      "       'independent', 'mashable', 'metro', 'mirror', 'mtv-news',\n",
      "       'mtv-news-uk', 'national-geographic', 'new-scientist',\n",
      "       'new-york-magazine', 'newsweek', 'nfl-news', 'polygon', 'recode',\n",
      "       'reddit-r-all', 'reuters', 'spiegel-online', 't3n', 'talksport',\n",
      "       'techcrunch', 'techradar', 'the-economist', 'the-guardian-au',\n",
      "       'the-guardian-uk', 'the-hindu', 'the-huffington-post',\n",
      "       'the-lad-bible', 'the-new-york-times', 'the-sport-bible',\n",
      "       'the-telegraph', 'the-times-of-india', 'the-verge',\n",
      "       'the-wall-street-journal', 'the-washington-post', 'time',\n",
      "       'usa-today', 'wired-de'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "# Check the data is good!\n",
    "print(len(newsfuzz_db))\n",
    "newsfuzz_db.head()\n",
    "pprint.pprint(np.unique(newsfuzz_db['source_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract guardian and daily mail articles\n",
    "articles_guard_dm=newsfuzz_db[newsfuzz_db['source_id'].isin(['the-guardian-uk','daily-mail'])]['article_raw'].tolist()\n",
    "articles_all=newsfuzz_db['article_raw'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dm=newsfuzz_db[newsfuzz_db['source_id'].isin(['daily-mail'])]['article_raw']\n",
    "articles_dm.head(1).tolist()\n",
    "\n",
    "dm_stops='Online Home News U S Sport TV Showbiz Femail Health Science Money Video Travel Fashion Finder Latest Headlines News World News Arts Headlines France Pictures Most'+ 'read Wires Discounts My Profile Logout Login Cookie Policy Feedback NEW ARTICLESHomeTopShare show ad'\n",
    "dm_stops_list=dm_stops.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yourself', 'above', 'why', 'down', 'over', 'into', 'while', 'an', 'they', 'now', 'have', 'should', 'Logout', 'Home', 'myself', 'he', 'no', 'him', 'where', 'both', 'hers', 'were', 'until', 'Sport', 'U', 'Cookie', 'too', 'My', 'herself', 'after', 'through', 'France', 'did', 'for', 'ARTICLESHomeTopShare', 'there', 'in', 'most', 'of', 'your', 'does', 'Money', 'Wires', 'S', 'its', 'had', 'few', 'i', 'those', 'Finder', 'Discounts', 'yours', 'TV', 'Showbiz', 'Video', 'the', 'Policy', 'if', 'very', 'himself', 'then', 'which', 'she', 'don', 'but', 'each', 'being', 'just', 'about', 'against', 'between', 'Online', 'is', 'am', 'on', 'theirs', 'not', 'how', 'Latest', 'whom', 'what', 'that', 'itself', 'again', 'has', 'all', 'me', 'before', 'than', 'NEW', 'Pictures', 'during', 'when', 'we', 'here', 'off', 'once', 'Feedback', 'can', 'Science', 't', 'will', 'same', 'or', 'own', 'other', 'from', 'nor', 'having', 'doing', 'because', 'World', 'our', 'under', 'his', 'such', 'their', 'only', 'are', 'with', 'this', 'some', 'show', 'by', 'Arts', 'Profile', 'them', 'do', 'these', 'been', 'up', 'and', 'as', 'her', 'be', 'Travel', 'Login', 'ourselves', 'was', 'below', 'to', 'News', 'Femail', 'it', 'Mostread', 'who', 'Health', 'Fashion', 'Headlines', 'out', 's', 'more', 'at', 'any', 'themselves', 'ours', 'further', 'you', 'yourselves', 'a', 'ad', 'so', 'my'}\n"
     ]
    }
   ],
   "source": [
    "# Import some standard bits from nltk for language structure\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "#Add the daily mail stops\n",
    "stop.update(dm_stops_list)\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to clean raw text based on stope words and punctuation\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the articles and assemble into a list\n",
    "articles_clean = []\n",
    "for article in articles_dm:\n",
    "    articles_clean.append(clean(article).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push articles into Document Term Matrix and create a dictionary\n",
    "dictionary = corpora.Dictionary(articles_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(article) for article in articles_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=50, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.000*\"show\"'), (1, '0.034*\"coach\"'), (2, '0.012*\"fire\"'), (3, '0.000*\"show\"'), (4, '0.000*\"star\"'), (5, '0.010*\"ussr\"'), (6, '0.007*\"prompted\"'), (7, '0.003*\"disgraceâ\\x80\\x99\"'), (8, '0.000*\"new\"'), (9, '0.038*\"may\"'), (10, '0.010*\"comment\"'), (11, '0.000*\"share\"'), (12, '0.006*\"new\"'), (13, '0.014*\"share\"'), (14, '0.010*\"u\"'), (15, '0.000*\"new\"'), (16, '0.006*\"star\"'), (17, '0.000*\"star\"'), (18, '0.000*\"show\"'), (19, '0.000*\"new\"'), (20, '0.003*\"booking\"'), (21, '0.000*\"show\"'), (22, '0.000*\"new\"'), (23, '0.030*\"skin\"'), (24, '0.005*\"steadfast\"'), (25, '0.000*\"show\"'), (26, '0.026*\"warhol\"'), (27, '0.017*\"hammond\"'), (28, '0.028*\"farron\"'), (29, '0.041*\"seed\"'), (30, '0.038*\"court\"'), (31, '0.006*\"comment\"'), (32, '0.043*\"drone\"'), (33, '0.015*\"inflation\"'), (34, '0.032*\"risk\"'), (35, '0.022*\"shot\"'), (36, '0.021*\"antibiotic\"'), (37, '0.009*\"trump\"'), (38, '0.007*\"london\"'), (39, '0.003*\"denouncing\"'), (40, '0.024*\"khrushchev\"'), (41, '0.003*\"parliamenthe\"'), (42, '0.020*\"share\"'), (43, '0.000*\"new\"'), (44, '0.006*\"show\"'), (45, '0.003*\"â\\x80\\x9ccontrolling\"'), (46, '0.024*\"brexit\"'), (47, '0.000*\"new\"'), (48, '0.045*\"isi\"'), (49, '0.006*\"new\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=50, num_words=1))\n",
    "ldamodel.save('newsapi_lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Alternative approach using Scikit learn below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "star dress model looks tony red gown awards york bikini\n",
      "Topic 1:\n",
      "grenfell tower reveals looks star dress york goes beach ex\n",
      "Topic 2:\n",
      "tower fire grenfell block building residents blaze floor inferno cladding\n",
      "Topic 3:\n",
      "bikini love star james reveals figure ex baby hammond looks\n",
      "Topic 4:\n",
      "congress dress tower reveals baseball love fire gunman kardashian husband\n",
      "Topic 5:\n",
      "facebook timeline posted automatically dog britain also south archive views\n",
      "Topic 6:\n",
      "mrs tory minister secretary election brexit mr mps labour theresa\n",
      "Topic 7:\n",
      "zoe flat former forbes footage food following follow florida floral\n",
      "Topic 8:\n",
      "watch flat floor pictured missing really secretary car group thought\n",
      "Topic 9:\n",
      "scalise watch shot shooting gunman baseball injured steve president fire\n",
      "Topic 10:\n",
      "water 50 ve 000 re picture four russia trying comey\n",
      "Topic 11:\n",
      "market harry come prince today support bridge business terror paul\n",
      "Topic 12:\n",
      "zoe flat former forbes footage food following follow florida floral\n",
      "Topic 13:\n",
      "church sasha huge town inside 000 right blaze american obama\n",
      "Topic 14:\n",
      "per fears since car market brexit election cars sent eight\n",
      "Topic 15:\n",
      "manchester group turned far terror city right leader 22 members\n",
      "Topic 16:\n",
      "staff hospital kate bridge visit victims royal terror emergency met\n",
      "Topic 17:\n",
      "zoe flat former forbes footage food following follow florida floral\n",
      "Topic 18:\n",
      "government court justice president watch fire driver mueller special national\n",
      "Topic 19:\n",
      "william seen prince festival watch game enjoying charity adorable sunday\n",
      "Topic 0:\n",
      "market staff hospital bridge harry kate visit support prince terror\n",
      "Topic 1:\n",
      "watch facebook william manchester seen prince sunday timeline posted group\n",
      "Topic 2:\n",
      "star dress ex york hot love red model exclusive premiere\n",
      "Topic 3:\n",
      "star dress looks love tony la manchester red model ex\n",
      "Topic 4:\n",
      "star love baby dress beau ex looks model awards bikini\n",
      "Topic 5:\n",
      "star dress looks love tony bikini model baby gown red\n",
      "Topic 6:\n",
      "star dress bikini looks figure model love reveals awards cut\n",
      "Topic 7:\n",
      "dress star reveals tower looks york grenfell ex love kardashian\n",
      "Topic 8:\n",
      "star model dress figure baby gown reveals bikini boyfriend love\n",
      "Topic 9:\n",
      "star dress looks red model love tony baby girlfriend ex\n",
      "Topic 10:\n",
      "star looks secretary dress love watch girlfriend bikini queen today\n",
      "Topic 11:\n",
      "court government russia 000 driver months justice comey state president\n",
      "Topic 12:\n",
      "fire tower grenfell building block floor residents watch blaze told\n",
      "Topic 13:\n",
      "star dress looks model york love bikini figure reveals ex\n",
      "Topic 14:\n",
      "star model love la dress baby reveals premiere flashes ex\n",
      "Topic 15:\n",
      "star love bikini looks dress reveals figure baby ex party\n",
      "Topic 16:\n",
      "star model gown red looks tony reveals la dress exclusive\n",
      "Topic 17:\n",
      "dress star looks baby awards model ex love reveals tony\n",
      "Topic 18:\n",
      "star looks model dress bikini party love figure reveals ex\n",
      "Topic 19:\n",
      "star dress model red looks gown hot tony love york\n"
     ]
    }
   ],
   "source": [
    "# documents = articles_guard_dm\n",
    "documents=articles_dm\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop)\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=50, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  NMF seems to work a good bit better at identifying non-bikini topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsfuzz",
   "language": "python",
   "name": "newsfuzz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
