{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch the data from the mysql server and throw it into a dataframe\n",
    "engine = create_engine('mysql+pymysql://newsfuzz:newsfuzzplease@newsfuzz.cuhvcgseshha.eu-west-2.rds.amazonaws.com:3306/newsfuzz', encoding='utf-8')\n",
    "newsfuzz_db = pd.io.sql.read_sql('SELECT * FROM newsfuzz_db_test', engine, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6533\n",
      "array(['abc-news-au', 'al-jazeera-english', 'ars-technica',\n",
      "       'associated-press', 'bbc-news', 'bbc-sport', 'bild', 'bloomberg',\n",
      "       'breitbart-news', 'business-insider', 'business-insider-uk',\n",
      "       'buzzfeed', 'cnbc', 'cnn', 'daily-mail', 'engadget',\n",
      "       'entertainment-weekly', 'espn', 'espn-cric-info', 'financial-times',\n",
      "       'focus', 'football-italia', 'fortune', 'four-four-two',\n",
      "       'fox-sports', 'google-news', 'gruenderszene', 'hacker-news', 'ign',\n",
      "       'independent', 'mashable', 'metro', 'mirror', 'mtv-news',\n",
      "       'mtv-news-uk', 'national-geographic', 'new-scientist',\n",
      "       'new-york-magazine', 'newsweek', 'nfl-news', 'polygon', 'recode',\n",
      "       'reddit-r-all', 'reuters', 'spiegel-online', 't3n', 'talksport',\n",
      "       'techcrunch', 'techradar', 'the-economist', 'the-guardian-au',\n",
      "       'the-guardian-uk', 'the-hindu', 'the-huffington-post',\n",
      "       'the-lad-bible', 'the-new-york-times', 'the-sport-bible',\n",
      "       'the-telegraph', 'the-times-of-india', 'the-verge',\n",
      "       'the-wall-street-journal', 'the-washington-post', 'time',\n",
      "       'usa-today', 'wired-de'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "# Check the data is good!\n",
    "print(len(newsfuzz_db))\n",
    "newsfuzz_db.head()\n",
    "pprint.pprint(np.unique(newsfuzz_db['source_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract guardian and daily mail articles\n",
    "articles_guard_dm=newsfuzz_db[newsfuzz_db['source_id'].isin(['the-guardian-uk','daily-mail'])] ['article_raw'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import some standard bits from nltk for language structure\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to clean raw text based on stope words and punctuation\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean the articles and assemble into a list\n",
    "articles_clean = []\n",
    "for article in articles_guard_dm:\n",
    "    articles_clean.append(clean(article).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Push articles into Document Term Matrix and create a dictionary\n",
    "dictionary = corpora.Dictionary(articles_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(article) for article in articles_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=50, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.000*\"show\"'), (1, '0.034*\"coach\"'), (2, '0.012*\"fire\"'), (3, '0.000*\"show\"'), (4, '0.000*\"star\"'), (5, '0.010*\"ussr\"'), (6, '0.007*\"prompted\"'), (7, '0.003*\"disgraceâ\\x80\\x99\"'), (8, '0.000*\"new\"'), (9, '0.038*\"may\"'), (10, '0.010*\"comment\"'), (11, '0.000*\"share\"'), (12, '0.006*\"new\"'), (13, '0.014*\"share\"'), (14, '0.010*\"u\"'), (15, '0.000*\"new\"'), (16, '0.006*\"star\"'), (17, '0.000*\"star\"'), (18, '0.000*\"show\"'), (19, '0.000*\"new\"'), (20, '0.003*\"booking\"'), (21, '0.000*\"show\"'), (22, '0.000*\"new\"'), (23, '0.030*\"skin\"'), (24, '0.005*\"steadfast\"'), (25, '0.000*\"show\"'), (26, '0.026*\"warhol\"'), (27, '0.017*\"hammond\"'), (28, '0.028*\"farron\"'), (29, '0.041*\"seed\"'), (30, '0.038*\"court\"'), (31, '0.006*\"comment\"'), (32, '0.043*\"drone\"'), (33, '0.015*\"inflation\"'), (34, '0.032*\"risk\"'), (35, '0.022*\"shot\"'), (36, '0.021*\"antibiotic\"'), (37, '0.009*\"trump\"'), (38, '0.007*\"london\"'), (39, '0.003*\"denouncing\"'), (40, '0.024*\"khrushchev\"'), (41, '0.003*\"parliamenthe\"'), (42, '0.020*\"share\"'), (43, '0.000*\"new\"'), (44, '0.006*\"show\"'), (45, '0.003*\"â\\x80\\x9ccontrolling\"'), (46, '0.024*\"brexit\"'), (47, '0.000*\"new\"'), (48, '0.045*\"isi\"'), (49, '0.006*\"new\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=50, num_words=1))\n",
    "ldamodel.save('newsapi_lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Alternative approach using Scikit learn below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "star new dress model trump son day old year looks\n",
      "Topic 1:\n",
      "edition switch opinion guardian business politics tech email supporter soccer\n",
      "Topic 2:\n",
      "tower grenfell block building residents london people floor west man\n",
      "Topic 3:\n",
      "bikini new shows reveals star figure ex james island baby\n",
      "Topic 4:\n",
      "brexit eu says britain talks theresa published british leave election\n",
      "Topic 5:\n",
      "watch mail mailonline police man post trump moment timeline comments\n",
      "Topic 6:\n",
      "london bridge attack market police killed victims final days published\n",
      "Topic 7:\n",
      "eu deal europe africa asia final figure film filmed filming\n",
      "Topic 8:\n",
      "manchester attack city police injured 22 victims attacks concert brother\n",
      "Topic 9:\n",
      "air force walking environment london street city final finally filming\n",
      "Topic 10:\n",
      "court charlie government appeal parents baby support anti street case\n",
      "Topic 11:\n",
      "north korea south president dennis asia kim washington selected east\n",
      "Topic 12:\n",
      "sessions russia campaign jeff comey calls meeting general private fbi\n",
      "Topic 13:\n",
      "trump donald president business ivanka general washington comey public politics\n",
      "Topic 14:\n",
      "dup tory deal election minister mrs party theresa mps secretary\n",
      "Topic 15:\n",
      "business google edt year post pay report living real brexit\n",
      "Topic 16:\n",
      "uber company report meeting travis member leave staff david sexual\n",
      "Topic 17:\n",
      "police shot shooting baseball steve public members man smith house\n",
      "Topic 18:\n",
      "staff hospital duchess kate visit attacks royal victims deal king\n",
      "Topic 19:\n",
      "william seen festival prince game charity enjoying looked royal watch\n"
     ]
    }
   ],
   "source": [
    "documents = articles_guard_dm\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "# display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsfuzz",
   "language": "python",
   "name": "newsfuzz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
